{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# hw7pr1.py ~ cs35 summer 2022   Natural Language!\n",
    "#\n",
    "\n",
    "# our libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Before we go further, let's make sure that you have these natural-language libraries working...\n",
    "# first, textblob, at https://textblob.readthedocs.io/en/dev/install.html\n",
    "# which installs nltk, the \"natural language toolkit\", https://www.nltk.org/\n",
    "import textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Natural language processing usually needs support files or \"corpora\" (or \"vectors\")\n",
    "# Try grabbing the punkt package first (for sentence-handling):\n",
    "import nltk\n",
    "nltk.download('punkt')   # this is nltk's sentence-handling routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\chung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\chung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\chung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\chung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\chung\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Then, try grabbing the corpora needed:\n",
    "# !python3 -m textblob.download_corpora\n",
    "# or\n",
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Some example texts!\n",
    "#\n",
    "\n",
    "# https://xkcd.com/1443/  Language Nerd\n",
    "xkcd_text = \"\"\"\n",
    "I don't mean to go all language nerd on you, \n",
    "but I just legit adverbed \"legit,\" verbed \"adverb,\" \n",
    "and adjectived \"language nerd.\"\n",
    "\"\"\"\n",
    "\n",
    "# from the Stanford treebank (#7 and #42)\n",
    "movie_review = \"\"\"\n",
    "Just the labor involved in creating the layered richness of the imagery in \n",
    "this chiaroscuro of madness and light is astonishing. Much of it comes from \n",
    "the brave, uninhibited performances by its lead actors.\n",
    "\"\"\"\n",
    "\n",
    "# the explanation from the treebank\n",
    "example_text = \"\"\"\n",
    "The underlying technology of this demo is based on a new type of \n",
    "Recursive Neural Network that builds on top of grammatical structures. \n",
    "You can also browse the Stanford Sentiment Treebank, the dataset on\n",
    "which this model was trained. Of course, no model is perfect!\n",
    "\"\"\"\n",
    "\n",
    "# from the Google API demo\n",
    "other_example = \"\"\"\n",
    "Google, headquartered in Mountain View (1600 Amphitheatre Pkwy, Mountain View, CA 940430), \n",
    "unveiled the new Android phone for $799 at the Consumer Electronic Show. \n",
    "Sundar Pichai said in his keynote that users love their new Android phones.\n",
    "\"\"\"\n",
    "\n",
    "# Stanford's treebank:  https://nlp.stanford.edu/sentiment/treebank.html\n",
    "# Google's site:  https://cloud.google.com/natural-language/#natural-language-api-demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the tokenized list-of-sentences from movie_review:\n",
      "len(LoS) is 2\n",
      "LoW is ['\\nJust the labor involved in creating the layered richness of the imagery in \\nthis chiaroscuro of madness and light is astonishing.', 'Much of it comes from \\nthe brave, uninhibited performances by its lead actors.']\n",
      "\n",
      "And the tokenized words - and punctuation - from other_example:\n",
      "len(LoW) is 46\n",
      "LoW is ['Google', ',', 'headquartered', 'in', 'Mountain', 'View', '(', '1600', 'Amphitheatre', 'Pkwy', ',', 'Mountain', 'View', ',', 'CA', '940430', ')', ',', 'unveiled', 'the', 'new', 'Android', 'phone', 'for', '$', '799', 'at', 'the', 'Consumer', 'Electronic', 'Show', '.', 'Sundar', 'Pichai', 'said', 'in', 'his', 'keynote', 'that', 'users', 'love', 'their', 'new', 'Android', 'phones', '.']\n",
      "\n",
      "part of speech 0 is ('I', 'PRP')\n",
      "part of speech 1 is ('do', 'VBP')\n",
      "part of speech 2 is (\"n't\", 'RB')\n",
      "part of speech 3 is ('mean', 'VB')\n",
      "part of speech 4 is ('to', 'TO')\n",
      "part of speech 5 is ('go', 'VB')\n",
      "part of speech 6 is ('all', 'DT')\n",
      "part of speech 7 is ('language', 'NN')\n"
     ]
    }
   ],
   "source": [
    "# tokenize with NLTK: sentences\n",
    "print(\"Here is the tokenized list-of-sentences from movie_review:\")\n",
    "LoS = nltk.sent_tokenize(movie_review)\n",
    "print(f\"len(LoS) is {len(LoS)}\")\n",
    "print(f\"LoW is {LoS}\")\n",
    "print()\n",
    "\n",
    "# words - and punctuation...\n",
    "print(\"And the tokenized words - and punctuation - from other_example:\")\n",
    "LoW = nltk.word_tokenize(other_example)\n",
    "print(f\"len(LoW) is {len(LoW)}\")\n",
    "print(f\"LoW is {LoW}\")\n",
    "print()\n",
    "\n",
    "# parts of speech!\n",
    "# Here is a list of parts-of-speech tags:  https://cs.nyu.edu/~grishman/jet/guide/PennPOS.html \n",
    "LoW = nltk.word_tokenize(xkcd_text)\n",
    "PoS = nltk.pos_tag(LoW)\n",
    "for i in range(8): # let's see the first eight\n",
    "    print(f\"part of speech {i} is {PoS[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing examples with textblob:\n",
      "Words: ['The', 'underlying', 'technology', 'of', 'this', 'demo', 'is', 'based', 'on', 'a', 'new', 'type', 'of', 'Recursive', 'Neural', 'Network', 'that', 'builds', 'on', 'top', 'of', 'grammatical', 'structures', 'You', 'can', 'also', 'browse', 'the', 'Stanford', 'Sentiment', 'Treebank', 'the', 'dataset', 'on', 'which', 'this', 'model', 'was', 'trained', 'Of', 'course', 'no', 'model', 'is', 'perfect']\n",
      "Sentences: [Sentence(\"\n",
      "The underlying technology of this demo is based on a new type of \n",
      "Recursive Neural Network that builds on top of grammatical structures.\"), Sentence(\"You can also browse the Stanford Sentiment Treebank, the dataset on\n",
      "which this model was trained.\"), Sentence(\"Of course, no model is perfect!\")]\n",
      "Parts-of-speech: [('The', 'DT'), ('underlying', 'VBG'), ('technology', 'NN'), ('of', 'IN'), ('this', 'DT'), ('demo', 'NN'), ('is', 'VBZ'), ('based', 'VBN'), ('on', 'IN'), ('a', 'DT'), ('new', 'JJ'), ('type', 'NN'), ('of', 'IN'), ('Recursive', 'NNP'), ('Neural', 'NNP'), ('Network', 'NNP'), ('that', 'WDT'), ('builds', 'VBZ'), ('on', 'IN'), ('top', 'NN'), ('of', 'IN'), ('grammatical', 'JJ'), ('structures', 'NNS'), ('You', 'PRP'), ('can', 'MD'), ('also', 'RB'), ('browse', 'VB'), ('the', 'DT'), ('Stanford', 'NNP'), ('Sentiment', 'NNP'), ('Treebank', 'NNP'), ('the', 'DT'), ('dataset', 'NN'), ('on', 'IN'), ('which', 'WDT'), ('this', 'DT'), ('model', 'NN'), ('was', 'VBD'), ('trained', 'VBN'), ('Of', 'IN'), ('course', 'NN'), ('no', 'DT'), ('model', 'NN'), ('is', 'VBZ'), ('perfect', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "# Let's try textblob!\n",
    "\n",
    "blob = textblob.TextBlob( example_text )\n",
    "print(\"Tokenizing examples with textblob:\")\n",
    "print(\"Words:\", blob.words)\n",
    "print(\"Sentences:\", blob.sentences)\n",
    "print(\"Parts-of-speech:\", blob.pos_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Let's try to create an example that confuses textblob...\n",
    "\n",
    "or, at least, causes it to get one or more parts-of-speech incorrect.\n",
    "\n",
    "An online guide to the parts-of-speech tags is [at this link](https://cs.nyu.edu/~grishman/jet/guide/PennPOS.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts-of-speech:\n",
      " [('Will', 'MD'), ('will', 'MD'), ('write', 'VB'), ('Will', 'NNP'), (\"'s\", 'POS'), ('will', 'MD'), ('on', 'IN'), ('the', 'DT'), ('other', 'JJ'), ('will', 'MD')]\n",
      "\n",
      "Parts-of-speech:\n",
      " [('Superlatives', 'NNS'), ('are', 'VBP'), ('superly', 'JJ'), ('super', 'NN')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    # Create - or find - a new sentence for which NLTK or textblob get one or more parts-of-speech wrong...\n",
    "#\n",
    "# Parts of speech:  https://cs.nyu.edu/~grishman/jet/guide/PennPOS.html \n",
    "\n",
    "example1 = \"Will will write Will's will on the other will.\"\n",
    "# Will is a name but TextBlob thinks it is a Modal (I don't really know what that is but it's not a noun)\n",
    "# That last will is a noun but instead TextBlob thinks it's a Modal.\n",
    "\n",
    "example2 = \"Superlatives are superly super.\"\n",
    "# Superly should be considered as an adverb and super should be an adjective...\n",
    "\n",
    "blob1 = textblob.TextBlob( example1 )\n",
    "blob2 = textblob.TextBlob( example2 )\n",
    "print(\"Parts-of-speech:\\n\", blob1.pos_tags)\n",
    "print()\n",
    "print(\"Parts-of-speech:\\n\", blob2.pos_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let textblob show off! Examples from the TextBlob QuickStart Tutorial, \n",
    "# at https://textblob.readthedocs.io/en/dev/quickstart.html\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Python', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('high-level', 'JJ'),\n",
       " ('general-purpose', 'JJ'),\n",
       " ('programming', 'NN'),\n",
       " ('language', 'NN')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = TextBlob(\"Python is a high-level, general-purpose programming language.\")\n",
    "wiki.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testimonial.sentiment.polarity=0.39166666666666666\n",
      "testimonial.sentiment.subjectivity=0.4357142857142857\n"
     ]
    }
   ],
   "source": [
    "testimonial = TextBlob(\"Textblob is amazingly simple to use. What great fun!\")\n",
    "print(f\"{testimonial.sentiment.polarity=}\")\n",
    "print(f\"{testimonial.sentiment.subjectivity=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beautiful is better than ugly. Sentiment(polarity=0.2166666666666667, subjectivity=0.8333333333333334)\n",
      "Explicit is better than implicit. Sentiment(polarity=0.5, subjectivity=0.5)\n",
      "Simple is better than complex. Sentiment(polarity=0.06666666666666667, subjectivity=0.41904761904761906)\n"
     ]
    }
   ],
   "source": [
    "zen = TextBlob(\"Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex.\")\n",
    "for sentence in zen.sentences:\n",
    "    print(sentence, sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence.words[2]='spaces'\n",
      "sentence.words[2].singularize()='space'\n",
      "sentence.words[-1]='level'\n",
      "sentence.words[-1].pluralize()='levels'\n"
     ]
    }
   ],
   "source": [
    "sentence = TextBlob('Use 4 spaces per indentation level.')\n",
    "print(f\"{sentence.words[2]=}\")\n",
    "print(f\"{sentence.words[2].singularize()=}\")\n",
    "print(f\"{sentence.words[-1]=}\")\n",
    "print(f\"{sentence.words[-1].pluralize()=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have good spelling!\n"
     ]
    }
   ],
   "source": [
    "# Cool!\n",
    "b = TextBlob(\"I havv goood speling!\")\n",
    "print(b.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gensim!\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Blade 17\n",
      " Volume Serial Number is CAA9-6C59\n",
      "\n",
      " Directory of c:\\Users\\chung\\OneDrive\\Desktop\\CS35\\week7_sum22\\week7_sum22\n",
      "\n",
      "07/14/2022  01:41 PM    <DIR>          .\n",
      "07/14/2022  01:41 PM    <DIR>          ..\n",
      "07/14/2022  01:19 PM             1,283 hw7ec.ipynb\n",
      "07/14/2022  01:19 PM             2,688 hw7pr0.ipynb\n",
      "07/14/2022  04:57 PM            51,431 hw7pr1.ipynb\n",
      "07/14/2022  01:19 PM             9,355 hw7pr2.ipynb\n",
      "07/14/2022  01:19 PM       138,432,415 word2vec_model.txt\n",
      "               5 File(s)    138,497,172 bytes\n",
      "               2 Dir(s)  365,692,334,080 bytes free\n"
     ]
    }
   ],
   "source": [
    "# The word-embeddings are in the file word2vec_model.txt\n",
    "# Make sure that file is here:\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load the model in  word2vec_model.txt ...\n",
      "Model loaded.\n",
      "\n",
      "The model built is KeyedVectors<vector_size=300, 43981 keys> \n",
      "\n",
      "The vocabulary has 43981 words\n",
      "Each word is a vector of size 300\n",
      "\n",
      "Try m.get_vector('python') to see a the vector for 'python'!\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x2414fb19330>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Create a model, m, with the line   m = read_word2vec_model()\n",
    "#\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "def read_word2vec_model(filename = \"word2vec_model.txt\"):  \n",
    "    \"\"\" a function that reads a word2vec model from the file\n",
    "        \"word2vec_model.txt\" and returns a model object that\n",
    "        we will usually name m or model...\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"Starting to load the model in \", filename, \"...\")\n",
    "        model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "        print(\"Model loaded.\\n\")\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  [WARNING]    The file {filename} was not found.     [WARNING]  \")\n",
    "        return None   # returning a placeholder, not a model\n",
    "\n",
    "    # let's print some attributes\n",
    "    print(\"The model built is\", model, \"\\n\")\n",
    "    print(\"The vocabulary has\", model.vectors.shape[0], \"words\")   # The vocabulary has 43981 words\n",
    "    print(\"Each word is a vector of size\", model.vector_size)  # 300\n",
    "    print(\"\\nTry m.get_vector('python') to see a the vector for 'python'!\\n\")\n",
    "    model.fill_norms()  # freezes the model, m, as-is (no more training)\n",
    "    # we weren't going to train more, so no worries (in week7, at least)\n",
    "    return model\n",
    "\n",
    "read_word2vec_model(\"word2vec_model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load the model in  word2vec_model.txt ...\n",
      "Model loaded.\n",
      "\n",
      "The model built is KeyedVectors<vector_size=300, 43981 keys> \n",
      "\n",
      "The vocabulary has 43981 words\n",
      "Each word is a vector of size 300\n",
      "\n",
      "Try m.get_vector('python') to see a the vector for 'python'!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# best to run this only once... or once in a while\n",
    "#\n",
    "m = read_word2vec_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That word is in m\n"
     ]
    }
   ],
   "source": [
    "if 'king' in m:\n",
    "    print(\"That word is in m\")\n",
    "else:\n",
    "    print(\"That word is NOT in m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.34064e-02,  1.02628e-02,  2.96526e-03,  4.81172e-02,\n",
       "       -8.83269e-03, -1.24499e-02,  3.85274e-02, -6.83062e-02,\n",
       "        1.76654e-02,  1.25172e-01, -8.34479e-02, -1.04310e-01,\n",
       "       -6.12400e-02, -8.58033e-03, -5.78752e-02, -5.85481e-02,\n",
       "        1.19452e-02,  1.79808e-03,  1.59830e-02,  4.44158e-02,\n",
       "        4.71077e-02,  3.88639e-02,  2.05255e-02,  4.71077e-02,\n",
       "        3.48261e-02, -6.09035e-02, -8.68128e-02,  2.06096e-02,\n",
       "        1.17769e-01, -1.07254e-02,  3.60037e-02,  2.12826e-02,\n",
       "        4.29017e-02,  1.37958e-01, -1.11040e-01,  2.89376e-02,\n",
       "        1.34593e-02,  2.01890e-03,  2.42268e-02,  5.95576e-02,\n",
       "        4.77807e-02, -7.97466e-02,  9.75802e-02,  4.91266e-02,\n",
       "        1.17769e-01, -8.24385e-03, -3.78544e-02,  1.14404e-02,\n",
       "       -1.88431e-02,  5.27859e-03, -5.58563e-02,  5.45103e-02,\n",
       "       -8.95046e-02,  6.93997e-03, -5.61928e-02,  4.67923e-04,\n",
       "       -4.97996e-02, -1.96002e-02,  1.48053e-02, -8.49621e-03,\n",
       "        6.39319e-02,  1.54109e-01,  3.30175e-03,  4.54253e-02,\n",
       "        3.39848e-02, -6.39319e-02, -3.44896e-02, -4.60983e-02,\n",
       "       -4.30699e-02,  9.75802e-02,  4.23969e-02,  1.83384e-02,\n",
       "       -6.12400e-02,  2.96106e-02, -7.52882e-03,  7.06616e-03,\n",
       "       -4.81172e-02,  8.66445e-03,  4.77807e-02, -3.63402e-02,\n",
       "        4.77807e-02,  3.06200e-02, -2.59092e-02, -7.36058e-03,\n",
       "        5.95576e-02,  1.59830e-02, -9.15235e-02,  3.07041e-03,\n",
       "        5.14820e-02,  1.30387e-02,  8.21020e-02, -4.29017e-02,\n",
       "       -7.50358e-02, -6.25859e-02,  1.02628e-02,  1.96843e-02,\n",
       "       -9.96833e-03,  4.29017e-03,  3.33119e-02, -7.97466e-02,\n",
       "        2.00208e-02,  2.30491e-02,  2.43951e-02, -1.06329e-01,\n",
       "       -7.40264e-02,  5.01361e-02, -1.47380e-01, -3.23865e-03,\n",
       "        5.31644e-02, -2.64140e-02,  9.95991e-02,  9.55613e-02,\n",
       "       -1.67585e-04, -4.71077e-02,  1.11713e-01, -8.47939e-02,\n",
       "       -1.04625e-03, -7.30169e-02,  4.30699e-02,  9.28695e-02,\n",
       "        7.03251e-02,  2.84329e-02, -6.93156e-02, -5.51833e-02,\n",
       "       -1.30387e-02, -4.13875e-02,  3.97051e-02, -1.41323e-02,\n",
       "       -1.36276e-02, -3.09565e-02,  2.18714e-03,  6.99886e-02,\n",
       "        6.42684e-02,  9.42154e-02,  2.17032e-02,  4.87901e-02,\n",
       "       -3.38166e-02,  4.77807e-02,  6.29224e-02,  5.98941e-02,\n",
       "        5.98941e-02, -8.17655e-02,  6.15765e-02,  2.18714e-02,\n",
       "        8.14290e-02, -7.20075e-02,  3.01153e-02, -5.72022e-02,\n",
       "       -2.72552e-02,  8.37844e-02, -3.06200e-02,  4.37429e-02,\n",
       "       -7.46994e-02, -5.98941e-02, -1.23826e-01, -2.84329e-02,\n",
       "       -2.23762e-02,  1.74971e-02,  4.67712e-02, -2.57410e-02,\n",
       "       -5.65292e-02,  3.97471e-03,  1.53437e-01, -7.43629e-02,\n",
       "       -3.83591e-02, -6.62873e-02,  5.88846e-02, -4.30699e-02,\n",
       "        9.14815e-04,  6.62873e-02, -6.02306e-02,  4.81172e-02,\n",
       "        1.00945e-01,  3.90321e-02,  2.05255e-02, -2.20397e-02,\n",
       "        3.43213e-02, -9.37948e-03,  6.77173e-03,  1.47212e-02,\n",
       "       -8.47939e-02,  2.20397e-02, -7.77277e-02, -5.82117e-02,\n",
       "        9.98936e-04,  2.82646e-02,  1.17769e-01,  1.48894e-02,\n",
       "        4.57618e-02,  4.91266e-02,  2.62457e-02,  2.06096e-02,\n",
       "       -4.10510e-02,  9.46360e-04, -2.17032e-02, -9.37948e-03,\n",
       "       -1.66139e-03, -2.82646e-02, -8.58033e-03, -1.37958e-01,\n",
       "       -3.68450e-02,  1.46370e-02,  2.67504e-02, -4.02098e-02,\n",
       "        2.54045e-02, -3.17977e-02,  3.71814e-02,  5.45103e-02,\n",
       "        1.46370e-02,  4.37429e-02,  1.24499e-02,  9.21965e-02,\n",
       "       -3.48261e-02, -1.04310e-01, -1.98525e-02,  1.74130e-02,\n",
       "        1.81386e-04, -7.13345e-02, -4.77807e-02, -3.09144e-03,\n",
       "       -9.58978e-03, -4.87901e-02,  7.13345e-02, -5.45103e-02,\n",
       "        4.40794e-02,  5.14820e-02, -7.73912e-03, -2.91058e-02,\n",
       "        4.22287e-02,  7.43629e-02, -7.36899e-02, -1.07675e-01,\n",
       "       -1.28537e-01,  1.40903e-03,  3.70132e-02,  3.68450e-02,\n",
       "        2.52363e-02,  3.09144e-03, -1.33752e-02, -4.47523e-02,\n",
       "        5.14820e-02, -7.40264e-02, -6.33535e-04,  3.41531e-02,\n",
       "        5.41739e-02, -3.93686e-02, -7.06616e-02,  3.41531e-02,\n",
       "        1.27191e-01, -6.79697e-02,  1.21975e-02,  3.76862e-02,\n",
       "        4.54253e-02,  5.75387e-02,  8.10925e-02,  3.61720e-02,\n",
       "       -1.70934e-01, -5.65292e-02, -5.38374e-02, -1.80019e-02,\n",
       "        3.54990e-02,  8.37844e-02, -6.49413e-02,  1.74971e-02,\n",
       "       -3.23024e-02, -2.30491e-02,  7.82324e-03,  2.62457e-02,\n",
       "        9.95991e-02,  1.07002e-01, -1.85066e-02,  7.87372e-02,\n",
       "        8.66445e-03,  2.33856e-02, -4.17240e-02, -7.43629e-02,\n",
       "       -9.42154e-02, -1.05992e-02, -1.16423e-01,  5.28279e-02,\n",
       "        8.04196e-02, -7.16710e-02,  1.28537e-01,  2.82646e-02,\n",
       "        8.68128e-02, -2.62457e-02, -1.60671e-02, -7.69706e-03,\n",
       "        1.03048e-02, -2.04414e-02, -1.60881e-03, -8.41209e-02,\n",
       "       -7.23440e-02, -9.89262e-02, -1.56465e-02, -6.12400e-02,\n",
       "       -9.62343e-02, -2.96106e-02,  3.14612e-02,  8.68128e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# let's see the meaning of 'king', 'queen', and 'python'!\n",
    "#\n",
    "m.get_vector('king')   # m.get_vector('queen')  m.get_vector('python')   m.get_vector('snake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable-assignment statements start to get noticeably \"meta\" ...\n",
    "python = m.get_vector('python')\n",
    "snake = m.get_vector('snake')\n",
    "language = m.get_vector('language')\n",
    "code = m.get_vector('code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(snake))  # this is the length of the vector...\n",
    "\n",
    "# the word2vec model provides unit vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66062933"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dot product is available in the numpy library\n",
    "np.dot(python, snake)\n",
    "\n",
    "# these are unit vectors, so this is the cosine \"similarity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which is 48.65206211455501 degrees\n"
     ]
    }
   ],
   "source": [
    "# we can find the angle between the two vectors\n",
    "deg = np.degrees(np.arccos(0.66063))  # converting from radians to degrees\n",
    "print(f\"which is {deg} degrees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6606292"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try the built-in similarity method:\n",
    "m.similarity('python','snake')   # should be the same .6606292..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3393707871437073"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.distance( 'python', 'snake' )   # This is 1 - the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9787417445331812"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.distance( 'python', 'coffee' )   # let's see..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "####  Let's explore dataset bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity w 'woman': 0.08992718160152435\n",
      "similarity w 'man': 0.126168891787529\n",
      "similarity w 'person': 0.22314053773880005\n"
     ]
    }
   ],
   "source": [
    "# with similarity, the biases of the datset can show through: let's check \"programmer\" vs \"woman\" and \"man\"\n",
    "#\n",
    "simw = m.similarity(\"programmer\",\"woman\")\n",
    "print(f\"similarity w 'woman': {simw}\")\n",
    "\n",
    "simm = m.similarity(\"programmer\",\"man\")\n",
    "print(f\"similarity w 'man': {simm}\")\n",
    "\n",
    "simp= m.similarity(\"programmer\",\"person\")   # try it!\n",
    "print(f\"similarity w 'person': {simp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Computing multiple similarities..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_snake  similarity: 0.6606292128562927\n",
      "python_coffee similarity: 0.02125825546681881\n",
      "snake_coffee  similarity: 0.07976286113262177\n"
     ]
    }
   ],
   "source": [
    "# Let's compare multiple similarities:\n",
    "\n",
    "python_snake = m.similarity('python','snake')\n",
    "python_coffee = m.similarity('python','coffee')\n",
    "snake_coffee = m.similarity('snake','coffee')\n",
    "\n",
    "print(f\"python_snake  similarity: {python_snake}\")   # try :4.2f after the variable for formatting\n",
    "print(f\"python_coffee similarity: {python_coffee}\")  # 4 characters wide, 2 places after the decimal point\n",
    "print(f\"snake_coffee  similarity: {snake_coffee}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python_snake  similarity: 0.6606292128562927\n",
      "python_coffee similarity: 0.02125825546681881\n",
      "snake_coffee similarity: 0.07976286113262177\n"
     ]
    }
   ],
   "source": [
    "# Comparing with multiple similarities\n",
    "\n",
    "# Let's compare multiple similarities:\n",
    "\n",
    "python_snake = m.similarity('python','snake')\n",
    "python_coffee = m.similarity('python','coffee')\n",
    "snake_coffee = m.similarity('snake','coffee')\n",
    "\n",
    "print(f\"python_snake  similarity: {python_snake}\")   # try :4.2f after the variable for formatting\n",
    "print(f\"python_coffee similarity: {python_coffee}\")  # 4 characters wide, 2 places after the decimal point\n",
    "print(f\"snake_coffee similarity: {snake_coffee}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhere, for example:\\n\\npython_snake  similarity: .66\\npython_coffee similarity: .02\\nsnake_coffee  similarity: .08\\n\\nSo, summing the similarities for each word separately:\\n  python:  .66 + .02 == .68\\n  coffee:  .08 + .02 == .10\\n  snake:   .66 + .08 == .74\\n\\n+++ In this case, \"coffee\" is the odd one out  (intuitive, in some ways)\\n\\n\\n# What do you think about python, serpent, snake?\\n# or python, serpent, snake, code?\\n\\n'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Let's define an \"odd-one-out\" from any collection of words, \n",
    "# simply by considering all possible similarities (and adding them up for each word)\n",
    "\n",
    "\"\"\"\n",
    "here, for example:\n",
    "\n",
    "python_snake  similarity: .66\n",
    "python_coffee similarity: .02\n",
    "snake_coffee  similarity: .08\n",
    "\n",
    "So, summing the similarities for each word separately:\n",
    "  python:  .66 + .02 == .68\n",
    "  coffee:  .08 + .02 == .10\n",
    "  snake:   .66 + .08 == .74\n",
    "\n",
    "+++ In this case, \"coffee\" is the odd one out  (intuitive, in some ways)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['snake', 'serpent', 'python', 'code', 'ai', 'ml', 'programming']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice that the split function makes creating lists-of-words a bit easier\n",
    "initial_words = \"snake serpent python code ai ml programming\".split()\n",
    "initial_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between python and snake:   0.66\n",
      "similarity between python and serpent:   0.45\n",
      "similarity between python and python:   1.00\n",
      "similarity between python and code:   0.11\n",
      "  __  ai  __ was not in the vocabulary\n",
      "similarity between python and ml:   0.08\n",
      "similarity between python and programming:   0.09\n",
      "LoS is [0.6606292, 0.44771382, 1.0, 0.10966147, 0.08480783, 0.090359524]\n",
      "LoW is ['snake', 'serpent', 'python', 'code', 'ml', 'programming']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# here is a _single_ keyword, with similarities computed against every word w in initial_words\n",
    "key = 'python'\n",
    "\n",
    "LoS = []\n",
    "LoW = []\n",
    "for w in initial_words:\n",
    "    if w in m: \n",
    "        similarity = m.similarity(key,w)\n",
    "        print(f\"similarity between {key} and {w}: {similarity:6.2f}\", )\n",
    "        LoS.append( similarity )\n",
    "        LoW.append( w )\n",
    "    else:\n",
    "        print(f\"  __  {w}  __ was not in the vocabulary\", )   # not every word will be present\n",
    "\n",
    "print(f\"LoS is {LoS}\")\n",
    "print(f\"LoW is {LoW}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity w 'woman': 0.06267661601305008\n",
      "similarity w 'man': 0.02842460200190544\n",
      "bias quantification; used 'person' as a neutral factor: 0.10806348919868469\n"
     ]
    }
   ],
   "source": [
    "# with similarity, the biases of the datset can show through: let's check \"president\" vs \"woman\" and \"man\"\n",
    "#\n",
    "simw = m.similarity(\"president\",\"woman\")\n",
    "print(f\"similarity w 'woman': {simw}\")\n",
    "\n",
    "simm = m.similarity(\"president\",\"man\")\n",
    "print(f\"similarity w 'man': {simm}\")\n",
    "\n",
    "# notice that the values provide a starting-point to _quantify_ the bias in the dataset\n",
    "# quantifying dataset bias is currently a very active area of research\n",
    "# it would also be possible to compare both of these with \n",
    "simp= m.similarity(\"president\",\"person\")   # try it!\n",
    "print(f\"bias quantification; used 'person' as a neutral factor: {simp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### From the cell above, we can see that 'president' and 'man' has the least similarity score, then 'president' and 'woman', and finally 'president' and 'person.' We use a term in m that serves as neutral between the words we are comparing (in this case, we are comparing man and woman to president). The neutral word here is 'person.' Although we can see that 'president' and 'woman' has 3x the similarity score compared to 'president' and 'man', we also see that the similarity score for 'president' and 'person' exceeds the other two. That means the a human being compared to president has a larger bias (for their similarity score) than when president is compared to a certain gender. \n",
    "\n",
    "##### We can also see that the comparison between 'president' and 'person' has a larger \"sway\" compared to the comparison for woman and man. Our dataset has proven this claim. We can compare these similarity differences to quantify the bias that we derived from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "president_woman  similarity: 0.06267661601305008\n",
      "president_man similarity: 0.02842460200190544\n",
      "woman_man  similarity: 0.7664012908935547\n"
     ]
    }
   ],
   "source": [
    "# Same comparison, this time with man and woman.\n",
    "\n",
    "president_woman = m.similarity('president','woman')\n",
    "president_man = m.similarity('president','man')\n",
    "woman_man = m.similarity('woman','man')\n",
    "\n",
    "print(f\"president_woman  similarity: {president_woman}\")   # try :4.2f after the variable for formatting\n",
    "print(f\"president_man similarity: {president_man}\")  # 4 characters wide, 2 places after the decimal point\n",
    "print(f\"woman_man  similarity: {woman_man}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nhere, for example:\\n\\npresident_woman  similarity: .063\\npresident_man similarity: .028\\nwoman_man  similarity: .766\\n\\nSo, summing the similarities for each word separately:\\n  president:  .063 + .028 == 0.091\\n  woman:  .063 + .766 == 0.829\\n  man:   .028 + .766 == .0.794\\n\\n+++ In this case, \"president\" is the odd one out  (intuitive, in some ways)\\n\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Let's define an \"odd-one-out\" from any collection of words, \n",
    "# simply by considering all possible similarities (and adding them up for each word)\n",
    "\n",
    "\"\"\"\n",
    "here, for example:\n",
    "\n",
    "president_woman  similarity: .063\n",
    "president_man similarity: .028\n",
    "woman_man  similarity: .766\n",
    "\n",
    "So, summing the similarities for each word separately:\n",
    "  president:  .063 + .028 == 0.091\n",
    "  woman:  .063 + .766 == 0.829\n",
    "  man:   .028 + .766 == .0.794\n",
    "\n",
    "+++ In this case, \"president\" is the odd one out  (intuitive, in some ways)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odd word out is wallet with a similarity score of 1.3832762762904167\n",
      "The odd word out is potato with a similarity score of 1.3954471051692963\n",
      "The odd word out is basketball with a similarity score of 1.3539883252233267\n",
      "The odd word out is game with a similarity score of 1.276320238597691\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# here is a signature line for odd_one_out (a starting point)\n",
    "#\n",
    "def odd_one_out( LoW, m ):\n",
    "    \"\"\" This function takes in a list of words LoW. It then finds each word's similarity score to every other word in LoW\n",
    "        as long as that word is in m. \n",
    "        It then outputs the odd one out, or the word with the smallest similarity score when compared to all other words in LoW.\n",
    "    \"\"\" \n",
    "    output = 999999\n",
    "    value = 0\n",
    "    odd_one = ''\n",
    "    for word in LoW:\n",
    "        if word in m:\n",
    "            for w in LoW:\n",
    "                if w in m:  # is the word, w present in the vocabulary?\n",
    "                    similarity = m.similarity(word,w)\n",
    "                    value += similarity\n",
    "                else:\n",
    "                    print(f\"  __  {w}  __ was not in the vocabulary\", )   # not every word will be present\n",
    "            if value < output:\n",
    "                output = value\n",
    "                odd_one = word\n",
    "                value = 0\n",
    "            else:\n",
    "                value = 0\n",
    "        else:\n",
    "            print(f\"  __  {word}  __ was not in the vocabulary\", )\n",
    "    print(f\"The odd word out is {odd_one} with a similarity score of {output}\")\n",
    "    \n",
    "LoW = ['apple', 'banana', 'wallet', 'peach']\n",
    "LoW2 = ['computer', 'machine', 'potato', 'algorithm']\n",
    "LoW3 = ['hat', 'jacket', 'clothes', 'shoes', 'basketball']\n",
    "LoW4 = ['game', 'turtle', 'lion', 'controller', 'fire']\n",
    "odd_one_out(LoW, m)         # SUCCESSFUL!\n",
    "odd_one_out(LoW2, m)        # SUCCESSFUL!\n",
    "odd_one_out(LoW3, m)        # SUCCESSFUL! \n",
    "odd_one_out(LoW4, m)        # Is this one successful? Personally, I thought 'fire' would be the odd one out..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create and run three examples - of at least 4 words each - for your odd_one_out function, e.g.,\n",
    "#        LoW = \"apple banana cat pear\".split()\n",
    "# Also, note if you would describe them as successful, unsuccessful, or \"other\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing similarity through a heat map\n",
    "\n",
    "# copy of the old starting code\n",
    "key = 'python'\n",
    "LoS = []\n",
    "LoW = []\n",
    "for w in initial_words:\n",
    "    if w in m:  # is the word, w present in the vocabulary?\n",
    "        similarity = m.similarity(key,w)\n",
    "        print(f\"similarity between {key} and {w}: {similarity:6.2f}\", )\n",
    "        LoS.append( similarity )\n",
    "        LoW.append( w )\n",
    "    else:\n",
    "        print(f\"  __  {w}  __ was not in the vocabulary\", )   # not every word will be present\n",
    "\n",
    "print(f\"LoS is {LoS}\")\n",
    "print(f\"LoW is {LoW}\")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "my_data_list = [ LoS ]\n",
    "my_dataframe = pd.DataFrame(my_data_list, columns=LoW)\n",
    "\n",
    "\n",
    "# Drawing a heatmap with the numeric values in each cell\n",
    "f, ax = plt.subplots(figsize=(15,10))  # (18, 12)\n",
    "sns.heatmap(data=my_dataframe, annot=True, fmt=\"4.2f\", linewidths=2, yticklabels=[\"python\"], square=True, cmap=\"Purples\", cbar=False, ax=ax)\n",
    "\n",
    "ylocs, ylabels = plt.yticks()\n",
    "plt.setp(ylabels, rotation=0, fontsize=15)\n",
    "xlocs, xlabels = plt.xticks()\n",
    "plt.setp(xlabels, rotation=70, fontsize=15)\n",
    "\"Result:\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "####  An alternative geometric view of word-vectors..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_wordvecs(wordlist, model):\n",
    "    \"\"\" example of finding an outlier with word2vec and graphically \"\"\"\n",
    "\n",
    "    for w in wordlist:\n",
    "        if w not in model:\n",
    "            print(\"Aargh - the model does not contain\", w)\n",
    "            print(\"Stopping...\")\n",
    "            return\n",
    "    #\n",
    "    # Next, we use PCA, Principal Components Analysis, to toss out 298 dimensions!\n",
    "    # and create a scatterplot of the words...\n",
    "    #\n",
    "    # Intuitive description of PCA:   https://setosa.io/ev/principal-component-analysis/\n",
    "    #\n",
    "    from sklearn.decomposition import PCA\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy\n",
    "\n",
    "    pca = PCA(n_components=2)             # 2 dimensions\n",
    "    pca_model = pca.fit(model.vectors)    # all 43,981 words with 300 numbers each!\n",
    "    LoM = [model.get_vector(w) for w in wordlist]   # list of models for each word w\n",
    "    \n",
    "    word_vectors = numpy.vstack(LoM)     # vstack creates a vertical column from a list\n",
    "    transformed_words = pca_model.transform(word_vectors)  # transform to our 2d space\n",
    "\n",
    "    # scatterplot\n",
    "    plt.scatter(transformed_words[:,0],transformed_words[:,1])\n",
    "    \n",
    "    # This is matplotlib's code for _annotating_ graphs (yay!)\n",
    "    for i, word in enumerate(wordlist):\n",
    "        plt.annotate(word, (transformed_words[i,0], transformed_words[i,1]), size='large')\n",
    "        # it's possible to be more sophisticated, but this is ok for now\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Example of calling visualize_wordvecs...\n",
    "#\n",
    "LoW = \"breakfast lunch dinner\".split()     #  cereal python, one two three four five twelve\n",
    "visualize_wordvecs(LoW, m)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1f0c8735478a48ff7ef3deb8c421f15aa5d573c59a98bc92eb9b829f28c47b33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
