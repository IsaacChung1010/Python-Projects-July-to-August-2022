{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "####   hw6pr3digits_dreamer\n",
    "+ imputing - or \"hallucinating\" - missing data using a trained neural network...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries!\n",
    "import numpy as np      # numpy is Python's \"array\" library\n",
    "import pandas as pd     # Pandas is Python's \"data\" library (\"dataframe\" == spreadsheet)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's read in our digits data...\n",
    "# \n",
    "# for read_csv, use header=0 when row 0 is a header row\n",
    "# \n",
    "filename = 'digits.csv'\n",
    "df = pd.read_csv(filename, header=0)   # encoding=\"utf-8\" et al.\n",
    "print(f\"{filename} : file read into a pandas dataframe.\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# let's drop that last column (dropping is usually by _name_):\n",
    "#\n",
    "#   if we want a list of the column names use df.columns\n",
    "coltodrop = df.columns[65]     # get last column name (with the url)\n",
    "df_clean = df.drop(columns=[coltodrop])  # drop by name is typical\n",
    "df_clean.info()                        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# let's keep our column names in variables, for reference\n",
    "#\n",
    "COLUMNS = df_clean.columns            # \"list\" of columns\n",
    "print(f\"COLUMNS: {COLUMNS}\")  \n",
    "\n",
    "# let's create a dictionary to look up any column index by name\n",
    "COL_INDEX = {}\n",
    "for i, name in enumerate(COLUMNS):\n",
    "    COL_INDEX[name] = i  # using the name (as key), look up the value (i)\n",
    "print(f\"COL_INDEX: {COL_INDEX}\")\n",
    "\n",
    "# and for our \"SPECIES\"!\n",
    "SPECIES = [ str(i) for i in range(0,10) ]  # list with a string at each index (index -> string)\n",
    "SPECIES_INDEX = { s:int(s) for s in SPECIES }  # dictionary mapping from string -> index\n",
    "\n",
    "# and our \"target labels\"\n",
    "print(f\"SPECIES: {SPECIES}\")  \n",
    "print(f\"SPECIES_INDEX: {SPECIES_INDEX}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# let's convert our dataframe to a numpy array, named A\n",
    "#    Our ML library, scikit-learn operates entirely on numpy arrays.\n",
    "#\n",
    "A = df_clean.to_numpy()    # .values gets the numpy array\n",
    "A = A.astype('float64')  # so many:  www.tutorialspoint.com/numpy/numpy_data_types.htm\n",
    "print(f\"A's shape is {A.shape}\")\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Now, to the digit-hallucinating part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# regression model that uses as input the first 48 pixels (pix0 to pix47)\n",
    "#                       and, as output, predicts the value of pix52\n",
    "#\n",
    "\n",
    "print(\"+++ Start of regression prediction of pix52! +++\\n\")\n",
    "\n",
    "X_all = A[:,0:48]  ### old: np.concatenate( (A[:,0:3], A[:,4:]),axis=1)  # horizontal concatenation\n",
    "y_all = A[:,52]    # y (labels) ... is all rows, column indexed 52 (pix52) only (actually the 53rd pixel, but ok)\n",
    "\n",
    "print(f\"y_all (just target values, pix52)   is \\n {y_all}\") \n",
    "print(f\"X_all (just features: 3 rows) is \\n {X_all[:3,:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# we scramble the data, to give a different TRAIN/TEST split each time...\n",
    "# \n",
    "indices = np.random.permutation(len(y_all))  # indices is a permutation-list\n",
    "\n",
    "# we scramble both X and y, necessarily with the same permutation\n",
    "X_all = X_all[indices]              # we apply the _same_ permutation to each!\n",
    "y_all = y_all[indices]              # again...\n",
    "print(\"labels (target)\\n\",y_all)\n",
    "print(\"features\\n\", X_all[:3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# We next separate into test data and training data ... \n",
    "#    + We will train on the training data...\n",
    "#    + We will _not_ look at the testing data to build the model\n",
    "#\n",
    "# Then, afterward, we will test on the testing data -- and see how well we do!\n",
    "#\n",
    "\n",
    "#\n",
    "# a common convention:  train on 80%, test on 20%    Let's define the TEST_PERCENT\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2)\n",
    "\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\\n\" )\n",
    "\n",
    "print(f\"Held-out data... (testing data: {len(y_test)})\")\n",
    "print(f\"y_test: {y_test}\\n\")\n",
    "print(f\"X_test (few rows): {X_test[0:5,:]}\")  # 5 rows\n",
    "print()\n",
    "print(f\"Data used for modeling... (training data: {len(y_train)})\")\n",
    "print(f\"y_train: {y_train}\\n\")\n",
    "print(f\"X_train (few rows): {X_train[0:5,:]}\")  # 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# for NNets, it's important to keep the feature values near 0, say -1. to 1. or so\n",
    "#    This is done through the \"StandardScaler\" in scikit-learn\n",
    "# \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "USE_SCALER = True   # this variable is important! It tracks if we need to use the scaler...\n",
    "\n",
    "# we \"train the scaler\"  (computes the mean and standard deviation)\n",
    "if USE_SCALER == True:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)  # Scale with the training data! ave becomes 0; stdev becomes 1\n",
    "else:\n",
    "    # this one does no scaling!  We still create it to be consistent:\n",
    "    scaler = StandardScaler(copy=True, with_mean=False, with_std=False) # no scaling\n",
    "    scaler.fit(X_train)  # still need to fit, though it does not change...\n",
    "\n",
    "scaler   # is now defined and ready to use...\n",
    "\n",
    "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "# Here is a fully-scaled dataset:\n",
    "\n",
    "X_all_scaled = scaler.transform(X_all)\n",
    "y_all_scaled = y_all.copy()      # not scaled\n",
    "\n",
    "\n",
    "# Here are our scaled training and testing sets:\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train) # scale!\n",
    "X_test_scaled = scaler.transform(X_test) # scale!\n",
    "\n",
    "y_train_scaled = y_train  # the predicted/desired labels are not scaled\n",
    "y_test_scaled = y_test  # not using the scaler\n",
    "\n",
    "def ascii_table(X,y):\n",
    "    \"\"\" print a table of binary inputs and outputs \"\"\"\n",
    "    print(f\"{'input ':>70s} -> {'pred':<5s} {'des.':<5s}\") \n",
    "    for i in range(len(y)):\n",
    "        s_to_show = str(X[i,:])\n",
    "        s_to_show = s_to_show[0:60]\n",
    "        print(f\"{s_to_show!s:>70s} -> {'?':<5s} {y[i]:<5.0f}\")   # !s is str ...\n",
    "    \n",
    "ascii_table(X_train_scaled[0:5,:],y_train_scaled[0:5])\n",
    "\n",
    "#\n",
    "# Note that the zeros have become -1's\n",
    "# and the 1's have stayed 1's\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# MLPRegressor predicts _floating-point_ outputs\n",
    "#\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "nn_regressor = MLPRegressor(hidden_layer_sizes=(6,7), \n",
    "                    max_iter=200,          # how many training epochs\n",
    "                    activation=\"tanh\",     # the activation function\n",
    "                    solver='sgd',          # the optimizer\n",
    "                    verbose=True,          # do we want to watch as it trains?\n",
    "                    shuffle=True,          # shuffle each epoch?\n",
    "                    random_state=None,     # use for reproducibility\n",
    "                    learning_rate_init=.1, # how much of each error to back-propagate\n",
    "                    learning_rate = 'adaptive')  # how to handle the learning_rate\n",
    "\n",
    "print(\"\\n\\n++++++++++  TRAINING:  begin  +++++++++++++++\\n\\n\")\n",
    "nn_regressor.fit(X_train_scaled, y_train_scaled)\n",
    "print(\"++++++++++  TRAINING:   end  +++++++++++++++\")\n",
    "\n",
    "print(f\"The (squared) prediction error (the loss) is {nn_regressor.loss_}\")\n",
    "print(f\"And, its square root: {nn_regressor.loss_ ** 0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# how did it do? now we're making progress (by regressing)\n",
    "#\n",
    "\n",
    "def ascii_table_for_regressor(Xsc,y,nn,scaler):\n",
    "    \"\"\" a table including predictions using nn.predict \"\"\"\n",
    "    predictions = nn.predict(Xsc) # all predictions\n",
    "    Xpr = scaler.inverse_transform(Xsc)  # Xpr is the \"X to print\": unscaled data!\n",
    "    # measure error\n",
    "    error = 0.0\n",
    "    # printing\n",
    "    print(f\"{'input ':>35s} ->  {'pred':^6s}  {'des.':^6s}  {'absdiff':^10s}\") \n",
    "    for i in range(len(y)):\n",
    "        pred = predictions[i]\n",
    "        desired = y[i]\n",
    "        result = abs(desired - pred)\n",
    "        error += result\n",
    "        # Xpr = Xsc   # if you'd like to see the scaled values\n",
    "        s_to_show = str(Xpr[i,:])\n",
    "        s_to_show = s_to_show[0:25]  # we'll just take 25 of these\n",
    "        print(f\"{s_to_show!s:>35s} ->  {pred:<+6.3f}  {desired:<+6.3f}  {result:^10.3f}\") \n",
    "\n",
    "    print(\"\\n\" + \"+++++   +++++      +++++   +++++   \")\n",
    "    print(f\"average abs error: {error/len(y)}\")\n",
    "    print(\"+++++   +++++      +++++   +++++   \")\n",
    "    \n",
    "#\n",
    "# let's see how it did on the test data \n",
    "# \n",
    "if True:\n",
    "    ascii_table_for_regressor(X_test_scaled,\n",
    "                            y_test_scaled,\n",
    "                            nn_regressor,\n",
    "                            scaler)   # this is our own f'n, above\n",
    "\n",
    "# and how it did on the training data!\n",
    "#\n",
    "if False:\n",
    "    ascii_table_for_regressor(X_train_scaled,\n",
    "                            y_train_scaled,\n",
    "                            nn_regressor,\n",
    "                            scaler)   # this is our own f'n, above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# let's create a final nn_regressor for pix52\n",
    "#\n",
    "pix52_final_regressor = MLPRegressor(hidden_layer_sizes=(6,7), \n",
    "                                    max_iter=400, \n",
    "                                    activation=\"tanh\",\n",
    "                                    solver='sgd', \n",
    "                                    verbose=False, \n",
    "                                    shuffle=True,\n",
    "                                    random_state=None, # reproduceability!\n",
    "                                    learning_rate_init=.1, \n",
    "                                    learning_rate = 'adaptive')\n",
    "\n",
    "print(\"\\n\\n++++++++++  TRAINING:  begin  +++++++++++++++\\n\\n\")\n",
    "pix52_final_regressor.fit(X_all_scaled, y_all_scaled)\n",
    "print(\"\\n\\n++++++++++  TRAINING:   end  +++++++++++++++\\n\\n\")\n",
    "\n",
    "print(f\"The (sq) prediction error (the loss) is {pix52_final_regressor.loss_}\") \n",
    "print(f\"So, the 'average' error per pixel is {pix52_final_regressor.loss_**0.5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# and, let's be sure we can use our \"finalized\" model:\n",
    "#\n",
    "\n",
    "def predict_from_model(pixels, model):\n",
    "    \"\"\" returns the prediction on the input pixels using the input model\n",
    "    \"\"\"\n",
    "    pixels_array = np.asarray([pixels])   # the extra sq. brackets are needed!\n",
    "    pixels_scaled = scaler.transform(pixels_array)  # need to use the scaler!\n",
    "    predicted = model.predict(pixels_scaled)\n",
    "    return predicted\n",
    "\n",
    "#\n",
    "# let's choose a digit to try...\n",
    "#\n",
    "row_to_show = 4                         # different indexing from X_all and y_all (they were reordered)\n",
    "numeral = A[row_to_show,64]\n",
    "print(f\"The numeral is a {int(numeral)}\\n\")\n",
    "\n",
    "all_pixels = A[row_to_show,0:64] \n",
    "first48pixels = A[row_to_show,0:48] \n",
    "\n",
    "pix52_predicted = predict_from_model(first48pixels,pix52_final_regressor)\n",
    "pix52_actual = A[row_to_show,52]\n",
    "\n",
    "print(f\"pix52 [predicted] vs. actual:  {pix52_predicted} vs. {pix52_actual}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Let's create a function to show one digit\n",
    "#\n",
    "\n",
    "def show_digit( pixels ):\n",
    "    \"\"\" should create a heatmap (image) of the digit contained in row \n",
    "            input: pixels should be a 1d numpy array\n",
    "            if it's more then 64 values, it will be truncated\n",
    "            if it's fewer than 64 values, 0's will be appended\n",
    "            \n",
    "    \"\"\"\n",
    "    # make sure the sizes are ok!\n",
    "    num_pixels = len(pixels)\n",
    "    if num_pixels != 64:\n",
    "        print(f\"(in show_digit) num_pixels was {num_pixels}; now set to 64\")\n",
    "    if num_pixels > 64:   # an elif would be a poor choice here, as I found!\n",
    "        pixels = pixels[0:64]\n",
    "    if num_pixels < 64:   \n",
    "        num_zeros = 64-len(pixels)\n",
    "        pixels = np.concatenate( (pixels, np.zeros(num_zeros)), axis=0 )\n",
    "        \n",
    "    pixels = pixels.astype(int)         # convert to integers for plotting\n",
    "    pixels = np.reshape(pixels, (8,8))  # make 8x8\n",
    "    # print(f\"The pixels are\\n{pixels}\")  \n",
    "    f, ax = plt.subplots(figsize=(9, 6))  # Draw a heatmap w/option of numeric values in each cell\n",
    "    \n",
    "    #my_cmap = sns.dark_palette(\"Purple\", as_cmap=True)\n",
    "    my_cmap = sns.light_palette(\"Gray\", as_cmap=True)    # all seaborn palettes: medium.com/@morganjonesartist/color-guide-to-seaborn-palettes-da849406d44f\n",
    "    # plot! annot=True to see the values...   palettes listed at very bottom of this notebook\n",
    "    sns.heatmap(pixels, annot=False, fmt=\"d\", linewidths=.5, ax=ax, cmap=my_cmap) # 'seismic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Another example of predicting one pixel\n",
    "#\n",
    "row_to_show = 42                         \n",
    "numeral = A[row_to_show,64]\n",
    "print(f\"The numeral is a {int(numeral)}\\n\")\n",
    "# show all from the original data\n",
    "show_digit( A[row_to_show,0:64] )   # show full original\n",
    "\n",
    "all_pixels = A[row_to_show,0:64].copy()\n",
    "first48pixels = all_pixels[0:48] \n",
    "\n",
    "pix52_predicted = predict_from_model(first48pixels,pix52_final_regressor)\n",
    "pix52_actual = A[row_to_show,52]\n",
    "\n",
    "print(f\"pix52 [predicted] vs. actual:  {pix52_predicted} {pix52_actual}\")\n",
    "\n",
    "# erase last 16 pixels\n",
    "all_pixels[48:64] = np.zeros(16)\n",
    "\n",
    "# show without pix52\n",
    "all_pixels[52] = 0         # omit this one\n",
    "show_digit( all_pixels )   # show without pixel 52\n",
    "\n",
    "# show with pix52\n",
    "all_pixels[52] = np.round(pix52_predicted)    # include this one\n",
    "show_digit( all_pixels )   # show with pixel 52\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Another example of using 48 to predict one pixel (pix52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Another example of predicting one pixel\n",
    "#\n",
    "row_to_show = 42                         \n",
    "numeral = A[row_to_show,64]\n",
    "print(f\"The numeral is a {int(numeral)}\\n\")\n",
    "\n",
    "all_pixels = A[row_to_show,0:64].copy()\n",
    "first48pixels = all_pixels[0:48] \n",
    "\n",
    "pix52_predicted = predict_from_model(first48pixels,pix52_final_regressor)\n",
    "pix52_actual = A[row_to_show,52]\n",
    "\n",
    "print(f\"pix52 [predicted] vs. actual:  {pix52_predicted} {pix52_actual}\")\n",
    "\n",
    "# erase last 16 pixels\n",
    "all_pixels[48:64] = np.zeros(16)\n",
    "\n",
    "# show without pix52\n",
    "all_pixels[52] = 0         # omit this one\n",
    "show_digit( all_pixels )   # show without pixel 52\n",
    "\n",
    "# show with pix52\n",
    "all_pixels[52] = np.round(pix52_predicted)    # include this one\n",
    "show_digit( all_pixels )   # show without pixel 52\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Plus, an example of visualizing 32 with and without pixel 52..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# let's choose a digit to try...\n",
    "#\n",
    "row_to_show = 42                         # different indexing from X_all and y_all (they were reordered)\n",
    "numeral = A[row_to_show,64]\n",
    "print(f\"The numeral is a {int(numeral)}\\n\")\n",
    "\n",
    "all_pixels = A[row_to_show,0:64].copy()\n",
    "first_pixels = all_pixels[0:48]    # should be 32!\n",
    "\n",
    "pix52_predicted = predict_from_model(first_pixels,pix52_final_regressor)\n",
    "pix52_actual = A[row_to_show,52]\n",
    "\n",
    "print(f\"pix52 [predicted] vs. actual:  {pix52_predicted} {pix52_actual}\")\n",
    "\n",
    "# erase last 32 pixels\n",
    "all_pixels[32:64] = np.zeros(32)\n",
    "show_digit( all_pixels )\n",
    "\n",
    "# set pix52\n",
    "all_pixels[52] = np.round(pix52_predicted)\n",
    "show_digit( all_pixels )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
